{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import HyperBandForBOHB\n",
    "from functools import partial\n",
    "\n",
    "# Load a sample dataset (you can replace this with your own dataset)\n",
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "\n",
    "# Define the training function\n",
    "def train_lightgbm(config, loss='std'):\n",
    "    model = lgb.LGBMClassifier(**config)\n",
    "\n",
    "    cv_scores = cross_validate(model, X, y, cv=5, scoring=\"accuracy\", n_jobs=-1, return_train_score=True)\n",
    "\n",
    "    # Calculate mean and standard deviation of cross-validation scores\n",
    "    mean_score = np.mean(cv_scores)\n",
    "    std_score = np.std(cv_scores)\n",
    "    \n",
    "    if loss == 'std_train':\n",
    "        score = std_score\n",
    "    elif loss == 'std':\n",
    "        score = std_score\n",
    "    elif loss == 'hybrid':\n",
    "        score = mean_score\n",
    "    elif loss == 'metric':\n",
    "        score = mean_score\n",
    "\n",
    "    # Use both mean and std as the metric to minimize\n",
    "    tune.report(mean_accuracy=mean_score, std_accuracy=std_score) \n",
    "\n",
    "\n",
    "# Define the search space for hyperparameters\n",
    "config_space = {\n",
    "    \"num_leaves\": tune.choice([20, 30, 40, 50]),\n",
    "    \"learning_rate\": tune.loguniform(1e-4, 1e-1),\n",
    "    \"subsample\": tune.uniform(0.5, 1.0),\n",
    "    \"colsample_bytree\": tune.uniform(0.5, 1.0),\n",
    "    \"reg_alpha\": tune.loguniform(1e-4, 1e2),\n",
    "    \"reg_lambda\": tune.loguniform(1e-4, 1e2),\n",
    "}\n",
    "\n",
    "# Define the BOHB scheduler\n",
    "bohb_hyperband = HyperBandForBOHB(\n",
    "    time_attr=\"training_iteration\", max_t=100, reduction_factor=2, grace_period=10\n",
    ")\n",
    "\n",
    "fmin_objective = partial(train_lightgbm, loss='std')\n",
    "# Set up the experiment configuration\n",
    "analysis = tune.run(\n",
    "    train_lightgbm,\n",
    "    config=config_space,\n",
    "    num_samples=10,  # Number of hyperparameter samples\n",
    "    metric=\"mean_accuracy\",  # Metric to minimize\n",
    "    mode=\"min\",\n",
    "    resources_per_trial={\"cpu\": 1},\n",
    "    search_alg=tune.bohb.BOHB(config_space=config_space, max_concurrent=4),\n",
    "    scheduler=bohb_hyperband,\n",
    ")\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_config = analysis.get_best_config(metric=\"mean_accuracy\", mode=\"min\")\n",
    "print(\"Best Hyperparameters:\", best_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import HyperBandForBOHB\n",
    "from functools import partial\n",
    "\n",
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "model = lgb.LGBMClassifier()\n",
    "\n",
    "cv_scores = cross_validate(\n",
    "    model, X, y, cv=5, scoring=\"accuracy\", n_jobs=-1, return_train_score=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.12932324, 0.13533711, 0.1248138 , 0.1248138 , 0.13232923]),\n",
       " 'score_time': array([0.00201416, 0.00200152, 0.00300169, 0.00200009, 0.00300789]),\n",
       " 'test_score': array([0.93859649, 0.96491228, 0.98245614, 0.98245614, 0.98230088]),\n",
       " 'train_score': array([1., 1., 1., 1., 1.])}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_scores['train_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.93859649, 0.96491228, 0.98245614, 0.98245614, 0.98230088])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_scores['test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.985072193758733"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.hstack((cv_scores[\"train_score\"], cv_scores[\"test_score\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get baseline score both for simple scoring metric and for the loss that we are going to create and try to beat that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare multiple loss functions and check accuracy but as well as stability and debugging etc.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare and explain SOTA hyperparameter tuning algorithms and cite sources. Neptune AI explains why but we can cite their sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For model debugging : Morris sensitivity analysis + Partial dependence plots + Permutation Importance + SHAP + Feature importance + DICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partial dependence plots to debug certain features and also to gain insights. We can also plot 2 features to extract insights and also add distributions or histograms or something to show the datapoins and their distribution. Although PDPs have disadvantages, check this article out https://christophm.github.io/interpretable-ml-book/pdp.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hedno_v2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
